{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two common sets of APIs to load a Keras model, a high-level API and a low-level API. This tutorial shows you how to load a Keras model using the SavedModel API under a distributed strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get update && apt-get install -y iputils-ping net-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow_datasets\n",
    "!pip install -q tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.1.0\n",
      "Eager Mode: True\n",
      "GPU not available.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "print(\"Tensorflow Version: {}\".format(tf.__version__))\n",
    "print(\"Eager Mode: {}\".format(tf.executing_eagerly()))\n",
    "print(\"GPU {} available.\".format(\"is\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"not\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with a Distributed Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "accelerators = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "  datasets, info = tfds.load(\n",
    "    name=\"fashion_mnist\", with_info=True, as_supervised=True)\n",
    "  fashion_train, fashion_test = datasets['train'], datasets['test']\n",
    "    \n",
    "  BUFFER_SIZE = 10000\n",
    "  BATCH_SIZE_PER_REPLICA = 64\n",
    "  BATCH_SIZE = BATCH_SIZE_PER_REPLICA * accelerators.num_replicas_in_sync\n",
    "\n",
    "  def normalize(image, label):\n",
    "    img = tf.cast(image, tf.float32)\n",
    "    img /= 255.0\n",
    "    return img, label\n",
    "\n",
    "  train_dataset = fashion_train.map(normalize).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "  test_dataset = fashion_test.map(normalize).cache().batch(BATCH_SIZE)\n",
    "\n",
    "  return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  def _model_body(inputs):\n",
    "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='elu')(inputs)\n",
    "    x = tf.keras.layers.MaxPool2D()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(units=64, activation='elu')(x)\n",
    "    output = tf.keras.layers.Dense(units=10, activation='softmax')(x)\n",
    "    return output\n",
    "  \n",
    "  inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "  outputs = _model_body(inputs)\n",
    "  model = tf.keras.Model(inputs, outputs)\n",
    "  return model\n",
    "\n",
    "def get_model():\n",
    "  with accelerators.scope():\n",
    "    model = build_model()\n",
    "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer=tf.keras.optimizers.Adam(), \n",
    "                  metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and preprocess the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, eval_dataset = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 28, 28, 1) (64,)\n"
     ]
    }
   ],
   "source": [
    "for _image, _label in train_dataset.take(1):\n",
    "  print(_image.shape, _label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model using a distributed strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 44s 47ms/step - loss: 0.4378 - accuracy: 0.8456\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 23s 25ms/step - loss: 0.3026 - accuracy: 0.8913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6ad47582b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(train_dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two common APIs are available for loading a `TF.Keras` model.\n",
    "* a high-level API: `tf.keras.Model.save` (or `model.save`) and `tf.keras.models.load_model`.\n",
    "* a low-level API: `tf.saved_model.save` and `tf.saved_model.load`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The TF.Keras APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must save the model without the scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/keras_save/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/keras_save/assets\n"
     ]
    }
   ],
   "source": [
    "keras_model_path = \"/tmp/keras_save\"\n",
    "model.save(keras_model_path)   # save() should be called out of the scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model without the Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 40s 42ms/step - loss: 0.2595 - accuracy: 0.9061\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.2199 - accuracy: 0.9205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6aba326c88>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_keras_model = tf.keras.models.load_model(keras_model_path)\n",
    "restored_keras_model.fit(train_dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the model, you can continue to train the model without compiling it again. The model is compiled before saving it and is saved as a Tensorflow standard proto format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model within the Specific Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 46s 50ms/step - loss: 0.2593 - accuracy: 0.9068\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.2216 - accuracy: 0.91941s - l\n"
     ]
    }
   ],
   "source": [
    "specific_scope = tf.distribute.OneDeviceStrategy('/cpu:0')\n",
    "with specific_scope.scope():\n",
    "  restored_keras_model_ds = tf.keras.models.load_model(keras_model_path)\n",
    "  restored_keras_model_ds.fit(train_dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here as you can see, you can restore and train the model on a different scope from the saved one.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `tf.saved_model` APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tf_saved/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tf_saved/assets\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "saved_model_path = \"/tmp/tf_saved\"\n",
    "tf.saved_model.save(model, saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model without the Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model using the `tf.saved_model` APIs provides low-level functionality (but as a foundation for lots of use cases) and returns an object, not a `TF.Keras` model. This object contains a function allowing to do inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_FUNCTION_KEY = 'serving_default'\n",
    "loaded = tf.saved_model.load(saved_model_path)\n",
    "inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each function is associated with a key. The `serving_default` is the default key for the inference function. To do the inference with the above function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict_dataset = eval_dataset.map(lambda image, label: image)\n",
    "for batch in predict_dataset.take(1):\n",
    "  print(inference_func(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model under a Distributed Manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distributed = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with distributed.scope():\n",
    "  loaded = tf.saved_model.load(saved_model_path)\n",
    "  inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]\n",
    "    \n",
    "  # define the dataset allowing for a distributed manner\n",
    "  dist_predict_dataset = distributed.experimental_distribute_dataset(predict_dataset)\n",
    "  \n",
    "  # calling the function in a distributed manner\n",
    "  for batch in dist_predict_dataset:\n",
    "    pred_res = distributed.experimental_run_v2(inference_func, args=(batch,))\n",
    "\n",
    "pred_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the inference function is the forward pass on the saved model, as a prediction operation. However, if you are going to continue training or to embed the loaded model into a bigger one, you need a further operation. A common way is to wrap this loaded object into a Keras layer to achieve the above goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bigger_model(loaded):\n",
    "  x = tf.keras.Input(shape=(28, 28, 1), name='input')\n",
    "  \n",
    "  # wrap the loaded model to a KerasLayer\n",
    "  keras_layer = hub.KerasLayer(loaded, trainable=True)(x)\n",
    "    \n",
    "  model = tf.keras.Model(x, keras_layer)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 43s 46ms/step - loss: 0.4259 - accuracy: 0.8482\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.2949 - accuracy: 0.8947\n"
     ]
    }
   ],
   "source": [
    "accel_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with accel_strategy.scope():\n",
    "  loaded = tf.saved_model.load(saved_model_path)\n",
    "  model = build_bigger_model(loaded)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, \n",
    "                optimizer=tf.keras.optimizers.Adam(), \n",
    "                metrics=['accuracy'])\n",
    "  model.fit(train_dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, you can wrap the loaded object into a bigger model or an another model using the `hub.KerasLayer` APIs. Such operations are useful for transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* about `Saving` the model: It is recommended to save the model using `model.save`. However, if your model is not constructed on the Keras APIs, you can save the model using the lower-level APIs.\n",
    "\n",
    "* about `Loading` the model: It depends on the purpose of what you want to do. If you want to get a Keras model, the `tf.keras.models.load_model()` API is suitable for you, on the other hand, if you want to deploy the model and do the inference task, the low-level API `tf.saved_model.load()` might be better for you.\n",
    "\n",
    "You can also mix these two different APIs at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/keras_save/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/keras_save/assets\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "# save the model using the high-level API\n",
    "model.save(keras_model_path)\n",
    "\n",
    "# load the model using the lower-level (not tf.keras) API\n",
    "with accel_strategy.scope():\n",
    "  loaded_model = tf.saved_model.load(keras_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caveats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can notice there is a special case that a Keras model does not have well-defined inputs.** For example, a sequential model can be created without a well-defined input. This comes with an error when the subclass module does not initialize the input as well. **In such a case, you have to stick with the low-level APIs on both saving and loading the model, otherwise, the model comes with errors.**\n",
    "\n",
    "It is easy to check the model whether it has well-defined inputs. Call the attribute `model.inputs` to check it is `None` or not. In general, the model's input would be defined after the model is used in `.fit()`, `.eval()`, `.predict()` or when calling `model(inputs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleModel(tf.keras.Model):\n",
    "  \n",
    "  output_layer_name = \"output_layer\"\n",
    "    \n",
    "  def __init__(self):\n",
    "    super(ExampleModel, self).__init__()\n",
    "    self._dense_layer = tf.keras.layers.Dense(\n",
    "      units=5, dtype=tf.float32, name=self.output_layer_name)\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    return self._dense_layer(inputs)\n",
    "\n",
    "examplemodel = ExampleModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras model <__main__.ExampleModel object at 0x7f6ac54e2cf8>, because its inputs are not defined.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras model <__main__.ExampleModel object at 0x7f6ac54e2cf8>, because its inputs are not defined.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed in `model.save().` Model <__main__.ExampleModel object at 0x7f6ac54e2cf8> cannot be saved because the input shapes have not been set. Usually, input shapes are automatically determined from calling .fit() or .predict(). To manually set the shapes, call model._set_inputs(inputs).\n",
      "WARNING:tensorflow:Skipping full serialization of Keras model <__main__.ExampleModel object at 0x7f6ac54e2cf8>, because its inputs are not defined.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras model <__main__.ExampleModel object at 0x7f6ac54e2cf8>, because its inputs are not defined.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f6ac54e27b8>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f6ac54e27b8>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/example/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/example/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call a high-level API `tf.saved_model.save()`.\n"
     ]
    }
   ],
   "source": [
    "example_path = \"/tmp/example\"\n",
    "\n",
    "if len(examplemodel.inputs) < 1:\n",
    "  try:\n",
    "    examplemodel.save(example_path)\n",
    "    print(\"Call a low-level API `model.save()`.\")\n",
    "  except Exception as e:\n",
    "    print(\"Failed in `model.save().` {}\".format(e))\n",
    "    tf.saved_model.save(examplemodel, example_path)\n",
    "    print(\"Call a high-level API `tf.saved_model.save()`.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
